# Machine Learning Basics (Python)

This directory covers **fundamental machine learning workflow principles**
that must be understood *before* applying any model or algorithm.

Rather than starting with models, this module focuses on:
- correct data splitting
- experimental design
- evaluation integrity
- prevention of data leakage

ë³¸ ë””ë ‰í† ë¦¬ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ì´ì „ì— ë°˜ë“œì‹œ ì´í•´í•´ì•¼ í•˜ëŠ”  
**ë°ì´í„° ë¶„ë¦¬, ê²€ì¦ ì„¤ê³„, ì¬í˜„ì„± í™•ë³´**ì˜ ê¸°ì´ˆë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.

ì¢‹ì€ ëª¨ë¸ ì„±ëŠ¥ì€ ì•Œê³ ë¦¬ì¦˜ë³´ë‹¤  
**ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ë‚˜ëˆ„ê³  ê²€ì¦í–ˆëŠ”ì§€**ì— ì˜í•´ ê²°ì •ë©ë‹ˆë‹¤.

---

## ğŸ¯ Objectives

- Understand why data must be split into train/test sets
- Prevent common data leakage scenarios
- Handle class imbalance correctly using stratification
- Respect temporal order in time-series data
- Avoid group-level leakage (patient/user/session level)
- Build reproducible machine learning experiments

---

## ğŸ“‚ Structure & Progress

Each file represents a core concept in ML experiment design.
Files are completed incrementally with daily commits.

ê° íŒŒì¼ì€ ë¨¸ì‹ ëŸ¬ë‹ ì‹¤í—˜ ì„¤ê³„ì˜ í•µì‹¬ ê°œë… í•˜ë‚˜ë¥¼ ë‹¤ë£¨ë©°,  
ì¼ì¼ í•™ìŠµ ë‹¨ìœ„ë¡œ ì ì§„ì ìœ¼ë¡œ ì™„ì„±ë©ë‹ˆë‹¤.

---

### âœ… Day 37 â€” Train / Test Split  
**`01_train_test_split.py`**

Best practices for splitting data into training and testing sets.

**Covered Scenarios**
- Random split with shuffle and reproducibility
- Stratified split for classification imbalance
- Time series split (no shuffle)
- Group-aware split (avoid entity leakage)

**Key Concepts**
- Data leakage and why it invalidates evaluation
- `random_state` for reproducibility
- When *not* to shuffle data
- Why group-level separation matters in real-world datasets

**Purpose**
- Ensure fair and reliable model evaluation
- Build experiments that can be trusted and reproduced
- Lay the foundation for cross-validation and model comparison

---

## ğŸ§  Why ML Basics Matter

Many machine learning failures are not caused by poor models,
but by **incorrect experimental design**.

Common pitfalls include:
- training on future information
- leaking user or patient identity across splits
- evaluating on data seen during training
- misrepresenting class distributions

Understanding these basics ensures that:
- reported performance is meaningful
- results generalize to real-world data
- conclusions are scientifically defensible

ë¨¸ì‹ ëŸ¬ë‹ì˜ ì‹ ë¢°ì„±ì€  
ëª¨ë¸ë³´ë‹¤ **ì‹¤í—˜ ì„¤ê³„ì˜ ì •í™•ì„±**ì—ì„œ ì‹œì‘ë©ë‹ˆë‹¤.

---

## ğŸ“Œ í•œêµ­ì–´ ìš”ì•½

- Day 37: ë‹¤ì–‘í•œ ë°ì´í„° íŠ¹ì„±ì— ë§ëŠ” train/test ë¶„ë¦¬ ì „ëµ ì •ë¦¬
- ë°ì´í„° ëˆ„ìˆ˜(leakage) ë°©ì§€ì˜ ì¤‘ìš”ì„± ì´í•´
- ë¶„ë¥˜, ì‹œê³„ì—´, ê·¸ë£¹ ë°ì´í„°ì— ëŒ€í•œ ë¶„ë¦¬ ê¸°ì¤€ í™•ë¦½

ì´ ëª¨ë“ˆì€  
**ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§ ì´ì „ ë‹¨ê³„ì—ì„œ ë°˜ë“œì‹œ í•„ìš”í•œ ì‹¤í—˜ ì„¤ê³„ ê¸°ì´ˆ**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

---

## ğŸš§ Status

**In progress â€” Machine Learning Basics (Day 37 started)**

Next recommended topics:
- Cross-validation (KFold, StratifiedKFold, GroupKFold, TimeSeriesSplit)
- Model evaluation metrics (accuracy vs ROC-AUC vs RMSE)
- Baseline models and sanity checks