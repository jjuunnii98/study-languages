"""
Day 38 â€” Machine Learning Metrics (Basics)

This file covers fundamental evaluation metrics for:
1. Classification
2. Regression

Evaluation is more important than the model itself.
A model without proper evaluation is meaningless.

ì´ íŒŒì¼ì€ ë¨¸ì‹ ëŸ¬ë‹ í‰ê°€ ì§€í‘œì˜ ê¸°ì´ˆë¥¼ ë‹¤ë£¬ë‹¤.

ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ì•Œê³ ë¦¬ì¦˜ë³´ë‹¤
"ì–´ë–¤ ì§€í‘œë¡œ í‰ê°€í–ˆëŠ”ê°€"ì— ì˜í•´ ë” í¬ê²Œ ì¢Œìš°ëœë‹¤.
"""

# --------------------------------------------------
# 1ï¸âƒ£ Imports
# --------------------------------------------------

import numpy as np
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    confusion_matrix,
    mean_squared_error,
    mean_absolute_error,
    r2_score
)

# --------------------------------------------------
# 2ï¸âƒ£ Classification Metrics
# --------------------------------------------------

"""
Classification example:
Binary classification (0 / 1)
"""

y_true = np.array([0, 1, 1, 0, 1, 0, 1, 1])
y_pred = np.array([0, 1, 0, 0, 1, 0, 1, 1])

# Accuracy
accuracy = accuracy_score(y_true, y_pred)

# Precision
precision = precision_score(y_true, y_pred)

# Recall
recall = recall_score(y_true, y_pred)

# F1 Score
f1 = f1_score(y_true, y_pred)

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)

print("=== Classification Metrics ===")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
print("Confusion Matrix:\n", cm)


"""
ğŸ“Œ í•œêµ­ì–´ ì„¤ëª…

Accuracy:
- ì „ì²´ ì˜ˆì¸¡ ì¤‘ ë§ì¶˜ ë¹„ìœ¨
- í´ë˜ìŠ¤ ë¶ˆê· í˜•ì¼ ë•Œ ì‹ ë¢°í•˜ê¸° ì–´ë ¤ì›€

Precision:
- ì–‘ì„±ìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ì‹¤ì œ ì–‘ì„± ë¹„ìœ¨
- False Positive ë¹„ìš©ì´ í´ ë•Œ ì¤‘ìš”

Recall:
- ì‹¤ì œ ì–‘ì„± ì¤‘ ì˜ˆì¸¡ ì„±ê³µ ë¹„ìœ¨
- False Negative ë¹„ìš©ì´ í´ ë•Œ ì¤‘ìš”

F1:
- Precisionê³¼ Recallì˜ ì¡°í™”í‰ê· 
- ë¶ˆê· í˜• ë°ì´í„°ì—ì„œ ìœ ìš©
"""

# --------------------------------------------------
# 3ï¸âƒ£ Regression Metrics
# --------------------------------------------------

"""
Regression example:
Continuous prediction
"""

y_true_reg = np.array([100, 120, 130, 150, 170])
y_pred_reg = np.array([110, 118, 125, 140, 180])

# MSE
mse = mean_squared_error(y_true_reg, y_pred_reg)

# RMSE
rmse = np.sqrt(mse)

# MAE
mae = mean_absolute_error(y_true_reg, y_pred_reg)

# R^2
r2 = r2_score(y_true_reg, y_pred_reg)

print("\n=== Regression Metrics ===")
print("MSE:", mse)
print("RMSE:", rmse)
print("MAE:", mae)
print("R^2:", r2)


"""
ğŸ“Œ í•œêµ­ì–´ ì„¤ëª…

MSE:
- ì˜¤ì°¨ ì œê³± í‰ê· 
- í° ì˜¤ì°¨ì— ë¯¼ê°

RMSE:
- MSEì˜ ì œê³±ê·¼
- ì›ë˜ ë‹¨ìœ„ë¡œ í•´ì„ ê°€ëŠ¥

MAE:
- ì ˆëŒ€ ì˜¤ì°¨ í‰ê· 
- ì´ìƒì¹˜ì— ëœ ë¯¼ê°

RÂ²:
- ì„¤ëª…ë ¥ ì§€í‘œ
- 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ
"""