# Text Processing (Python Libraries â€” 06)

This module focuses on **production-grade text preprocessing and transformation**
using Python.

Rather than treating text as simple strings, this module approaches it as a  
**feature engineering system** â€” transforming raw, unstructured text into
structured, model-ready representations suitable for analytics,
machine learning, and NLP pipelines.

ë³¸ ëª¨ë“ˆì€ Python ê¸°ë°˜ì˜ **ì‹¤ë¬´ ìˆ˜ì¤€ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì„¤ê³„**ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.  
í…ìŠ¤íŠ¸ë¥¼ ë‹¨ìˆœ ë¬¸ìì—´ì´ ì•„ë‹ˆë¼,  
**ë¹„ì •í˜• ë°ì´í„° â†’ ì •í˜• í”¼ì²˜ë¡œ ë³€í™˜í•˜ëŠ” ì—”ì§€ë‹ˆì–´ë§ ëŒ€ìƒ**ìœ¼ë¡œ ì ‘ê·¼í•©ë‹ˆë‹¤.

---

## ğŸ¯ Learning Objectives

After completing this module, you will be able to:

- Normalize noisy real-world text deterministically  
- Extract structured information using regular expressions  
- Design reusable tokenization and cleaning pipelines  
- Convert unstructured text into ML-ready feature spaces  
- Implement interpretable baseline NLP models  
- Understand how preprocessing affects downstream model performance  

---

## ğŸ“‚ Files & Progress

---

### âœ… Day 41 â€” Regex Fundamentals  
`01_regex_basics.py`

**Core Topics**

- `re.findall()` for multi-pattern extraction  
- Email / digit / keyword pattern detection  
- `re.sub()` for deterministic normalization  
- `re.match()` vs `re.search()` comparison  
- `re.compile()` for reusable and optimized patterns  
- Capturing groups (`()`) for structured extraction  

**í•œêµ­ì–´ ìš”ì•½**

- ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜ ì •ë³´ ì¶”ì¶œ ì„¤ê³„  
- í…ìŠ¤íŠ¸ ì •ê·œí™” ì²˜ë¦¬ ì „ëµ  
- match / search ë™ì‘ ì°¨ì´ ì´í•´  
- compileì„ í†µí•œ ì„±ëŠ¥ ë° ì¬ì‚¬ìš©ì„± ê°œì„   
- ê·¸ë£¹ ìº¡ì²˜ ê¸°ë°˜ êµ¬ì¡°í™”ëœ ë°ì´í„° ìƒì„±  

---

### âœ… Day 42 â€” Tokenization & Cleaning  
`02_tokenization_cleaning.py`

**Core Topics**

- Lowercasing and normalization strategies  
- Whitespace and punctuation handling  
- Regex-based tokenization logic  
- Stopword-style filtering rules  
- Custom cleaning function architecture  
- Reusable preprocessing pipeline design  

**í•œêµ­ì–´ ìš”ì•½**

- í…ìŠ¤íŠ¸ í‘œì¤€í™” ë° ì •ê·œí™” ì „ëµ  
- ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±° êµ¬ì¡° ì„¤ê³„  
- í† í° ë¶„ë¦¬ ë¡œì§ êµ¬í˜„  
- ë¶ˆí•„ìš” ë‹¨ì–´ ì œê±° ê·œì¹™ ì„¤ê³„  
- ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì„±  

---

### âœ… Day 43 â€” Simple Sentiment Baseline  
`03_simple_sentiment_baseline.py`

**Core Topics**

- Lexicon-based sentiment scoring  
- Positive / negative word dictionary construction  
- Negation handling (e.g., *not good* â†’ negative)  
- Intensifier logic (e.g., *very good*)  
- End-to-end pipeline:  
  - normalization â†’ tokenization â†’ scoring â†’ evaluation  
- Basic accuracy computation  
- Error case inspection  

**Architectural Focus**

- Explainable rule-based model  
- Deterministic scoring logic  
- Baseline comparison point for future ML models  

**í•œêµ­ì–´ ìš”ì•½**

- ì‚¬ì „ ê¸°ë°˜ ê°ì„± ì ìˆ˜í™” ì„¤ê³„  
- ë¶€ì •ì–´ ì²˜ë¦¬ êµ¬ì¡° êµ¬í˜„  
- ê°•ì¡°ì–´ ë¡œì§ ì„¤ê³„  
- ì „ì²˜ë¦¬ë¶€í„° í‰ê°€ê¹Œì§€ ì „ì²´ íë¦„ êµ¬í˜„  
- ì„¤ëª… ê°€ëŠ¥í•œ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ êµ¬ì¶•  
- í–¥í›„ ML ëª¨ë¸ê³¼ ë¹„êµ ê¸°ì¤€ ë§ˆë ¨  

---

## ğŸ§  Architectural Perspective

Text preprocessing is not cosmetic cleaning â€”  
it is a **core modeling stage**.

Poor preprocessing results in:

- Noisy feature representations  
- Reduced model stability  
- Increased overfitting risk  
- Low interpretability  

Well-designed preprocessing ensures:

- Reproducibility  
- Stable feature space  
- Robust model behavior  
- Scalable pipeline architecture  

í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ëŠ” ëª¨ë¸ ì„±ëŠ¥ì„ ê²°ì •í•˜ëŠ” í•µì‹¬ ë‹¨ê³„ì…ë‹ˆë‹¤.  
ì „ì²˜ë¦¬ í’ˆì§ˆì´ ê³§ ëª¨ë¸ í’ˆì§ˆì„ ì¢Œìš°í•©ë‹ˆë‹¤.

ì˜ ì„¤ê³„ëœ ì „ì²˜ë¦¬ëŠ”  
**ì¬í˜„ì„±, ì•ˆì •ì„±, í•´ì„ ê°€ëŠ¥ì„±, í™•ì¥ì„±**ì„ ë™ì‹œì— ë³´ì¥í•©ë‹ˆë‹¤.

---

## ğŸ”„ Conceptual Pipeline

```text
Raw Text
    â†“
Normalization
    â†“
Regex-Based Extraction
    â†“
Tokenization
    â†“
Cleaning / Filtering
    â†“
Feature Engineering
    â†“
Baseline Modeling
    â†“
ML / NLP Model Input