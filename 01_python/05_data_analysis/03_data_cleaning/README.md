# ğŸ§¹ Data Cleaning â€” 03_data_cleaning (Python Data Analysis)

This directory implements a **production-aware data cleaning architecture**
for analytics and machine learning pipelines.

Data cleaning is not a cosmetic step.
It is a structural control layer that ensures:

- correctness (no silent logical errors)
- statistical stability (distribution robustness)
- modeling safety (reduced distortion)
- reproducibility (rule-based transformations)

ë³¸ ë””ë ‰í† ë¦¬ëŠ” ë¶„ì„/ML íŒŒì´í”„ë¼ì¸ì—ì„œ í•„ìš”í•œ  
**ì‹¤ë¬´í˜• ë°ì´í„° í´ë¦¬ë‹ ì•„í‚¤í…ì²˜**ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

ë°ì´í„° í´ë¦¬ë‹ì€ ë‹¨ìˆœ ì „ì²˜ë¦¬ê°€ ì•„ë‹ˆë¼,

- ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨
- ê²°ì¸¡/ì´ìƒê°’ ì²˜ë¦¬ ì „ëµ ìˆ˜ë¦½
- ë¶„í¬ ì•ˆì •ì„± í™•ë³´
- ì¬í˜„ ê°€ëŠ¥í•œ ì²˜ë¦¬ ê·œì¹™ êµ¬ì¶•

ì„ ëª©í‘œë¡œ í•˜ëŠ” í•µì‹¬ ë‹¨ê³„ì…ë‹ˆë‹¤.

---

# ğŸ¯ Learning Objectives

After completing this module, you will be able to:

- Diagnose missingness magnitude and patterns
- Apply structured imputation strategies safely
- Detect outliers using robust statistical rules
- Choose between cap / drop / flag strategies rationally
- Preserve modeling integrity (avoid leakage & distortion)
- Build reusable cleaning utilities for scalable pipelines

ë³¸ ëª¨ë“ˆ ì™„ë£Œ í›„ ë‹¤ìŒì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- ê²°ì¸¡ì¹˜ ê·œëª¨ ë° íŒ¨í„´ ì²´ê³„ì  ì§„ë‹¨
- êµ¬ì¡°ì  ëŒ€ì²´(imputation) ì „ëµ ì„¤ê³„
- IQR/MAD ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€
- cap / drop / flag ì „ëµì„ ìƒí™©ì— ë§ê²Œ ì„ íƒ
- ëª¨ë¸ ì™œê³¡ì„ ìµœì†Œí™”í•˜ëŠ” ì•ˆì „í•œ ì²˜ë¦¬ êµ¬ì¡° ì„¤ê³„
- íŒŒì´í”„ë¼ì¸ì— ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í´ë¦¬ë‹ ìœ í‹¸ êµ¬í˜„

---

# ğŸ“‚ Files & Progress

---

## âœ… Day 54 â€” Missing Values Handling  
`01_missing_values.py`

### Core Capabilities

#### 1ï¸âƒ£ Missing Profiling
- Column-level missing count & percentage
- Missing pattern detection (co-missing columns)
- Prioritization of high-missing features

#### 2ï¸âƒ£ Strategy Patterns
- Drop rows / Drop columns (threshold-based)
- Numeric imputation:
  - mean
  - median
- Categorical imputation:
  - mode
  - constant (e.g., `"Unknown"`)
- Group-based imputation:
  - segment median
  - segment mode
- Time-aware imputation:
  - forward fill / backward fill
  - linear interpolation

#### 3ï¸âƒ£ Modeling-Safe Features
- Missing flag feature generation (`__is_missing`)
- Before/After comparison report
- Leakage-aware mindset (rule separation)

---

### ğŸ§  Why Day 54 Matters

Most modeling instability originates from:

- Hidden missing clusters
- Segment-dependent missing bias
- Improper global imputation
- Leakage during train/test split

Day 54 establishes:

- Structured diagnostics
- Policy-based imputation
- Reproducible missing handling

---

## âœ… Day 55 â€” Outlier Handling  
`02_outlier_handling.py`

### Core Capabilities

#### 1ï¸âƒ£ Robust Detection Methods
- IQR rule (Q1 âˆ’ kÂ·IQR / Q3 + kÂ·IQR)
- MAD-based robust z-score
- Percentile boundary detection

#### 2ï¸âƒ£ Policy-Based Actions
- Cap (Winsorization) â†’ recommended default
- Drop rows â†’ only when justified
- Flag only â†’ preserve signal for modeling

#### 3ï¸âƒ£ Reporting & Governance
- Column-level outlier count & rate
- Applied thresholds logging
- Row-drop impact tracking
- Reproducible policy object (`OutlierPolicy`)

---

### ğŸ§  Why Day 55 Matters

Outliers can:

- Distort mean & variance
- Break linear models
- Inflate loss functions
- Create unstable gradient behavior

Blind removal is dangerous.

Day 55 enforces:

- Explicit detection rules
- Controlled impact reduction
- Documented transformation policies

---

# ğŸ§  Integrated Cleaning Flow (Day 54 â†’ 55)

```text
Raw Dataset
    â†“
Schema & dtype validation
    â†“
Missing Profiling (count / pattern)
    â†“
Missing Handling (drop / impute / flag)
    â†“
Outlier Detection (IQR / MAD)
    â†“
Outlier Action (cap / drop / flag)
    â†“
Beforeâ€“After Validation Report
    â†“
Clean Dataset for EDA / Modeling